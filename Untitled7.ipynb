{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandasouzx/Trabalho-final-IA/blob/dev/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kzi7yM4FJcsv"
      },
      "outputs": [],
      "source": [
        "# 1. Instalação e Importação\n",
        "!pip install optuna lightgbm scikit-learn -q\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.stats import uniform, randint, loguniform\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LbG5LBBvJeq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39d1bf2-e257-478f-a255-43f039982c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (327208, 32), Colunas: ['DT_NOTIFIC', 'CS_SEXO', 'CO_RG_RESI', 'ID_MN_RESI', 'CS_ZONA', 'NU_IDADE_N', 'CS_ESCOL_N', 'CS_RACA', 'SG_UF', 'CS_GESTANT', 'PUERPERA', 'DIABETES', 'PNEUMOPATI', 'IMUNODEPRE', 'RENAL', 'OBESIDADE', 'OBES_IMC', 'CARDIOPATI', 'SIND_DOWN', 'HEPATICA', 'FATOR_RISC', 'FEBRE', 'TOSSE', 'GARGANTA', 'DESC_RESP', 'DIARREIA', 'VOMITO', 'FADIGA', 'SATURACAO', 'DISPNEIA', 'VACINA', 'EVOLUCAO']\n",
            "Nulos por coluna:\n",
            " DT_NOTIFIC         0\n",
            "CS_SEXO            0\n",
            "CO_RG_RESI     48106\n",
            "ID_MN_RESI        25\n",
            "CS_ZONA        34702\n",
            "NU_IDADE_N         0\n",
            "CS_ESCOL_N     96459\n",
            "CS_RACA        12619\n",
            "SG_UF             25\n",
            "CS_GESTANT         0\n",
            "PUERPERA      196353\n",
            "DIABETES      165794\n",
            "PNEUMOPATI    192134\n",
            "IMUNODEPRE    194155\n",
            "RENAL         192373\n",
            "OBESIDADE     191163\n",
            "OBES_IMC      317692\n",
            "CARDIOPATI    155123\n",
            "SIND_DOWN     195921\n",
            "HEPATICA      195676\n",
            "FATOR_RISC    118011\n",
            "FEBRE          39885\n",
            "TOSSE          34407\n",
            "GARGANTA       81845\n",
            "DESC_RESP      54843\n",
            "DIARREIA       85317\n",
            "VOMITO         89819\n",
            "FADIGA        176532\n",
            "SATURACAO      50831\n",
            "DISPNEIA       35513\n",
            "VACINA         66213\n",
            "EVOLUCAO           1\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        " #1.1 EDA\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "print(f\"Shape: {df.shape}, Colunas: {df.columns.tolist()}\")\n",
        "print(\"Nulos por coluna:\\n\", df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6glah2K8BZ8F"
      },
      "outputs": [],
      "source": [
        "# 2. Preprocessamento\n",
        "def preprocess_data(df, is_train=True, mortalidade_uf=None):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Drop early irrelevantes (PDF: opcional/altos nulos)\n",
        "    cols_to_drop_early = ['DT_NOTIFIC', 'OBES_IMC', 'VOMITO', 'TOSSE', 'PUERPERA', 'CO_RG_RESI', 'ID_MN_RESI']\n",
        "    for col in cols_to_drop_early:\n",
        "        if col in df.columns:\n",
        "            df.drop(col, axis=1, inplace=True, errors='ignore')\n",
        "            print(f\"Dropping {col} early.\")\n",
        "\n",
        "    # Handle SATURACAO before converting other columns to category\n",
        "    if 'SATURACAO' in df.columns:\n",
        "        df['SATURACAO'] = pd.to_numeric(df['SATURACAO'], errors='coerce').fillna(df['SATURACAO'].median() if df['SATURACAO'].isnull().sum() < len(df) else 0)\n",
        "\n",
        "\n",
        "    # Lista de colunas que são essencialmente categóricas (excluding SATURACAO)\n",
        "    cols_to_process_as_category = [\n",
        "      'DIABETES', 'PNEUMOPATI', 'IMUNODEPRE', 'RENAL', 'OBESIDADE',\n",
        "      'CARDIOPATI', 'SIND_DOWN', 'HEPATICA', 'FATOR_RISC', 'FEBRE',\n",
        "      'GARGANTA', 'DESC_RESP', 'DIARREIA', 'FADIGA',\n",
        "      'DISPNEIA', 'VACINA', 'CS_RACA', 'CS_GESTANT', 'CS_ZONA'\n",
        "    ]\n",
        "\n",
        "    for col in cols_to_process_as_category:\n",
        "        if col in df.columns:\n",
        "            # 1. Preenche o valor nulo com um número (pode ser 9, -1, etc.)\n",
        "            # Usamos string para garantir que não será tratado como número\n",
        "            fill_value = '9'\n",
        "            df[col] = df[col].fillna(fill_value)\n",
        "\n",
        "            # 2. Garante que todos os valores sejam strings antes de converter\n",
        "            df[col] = df[col].astype(str)\n",
        "\n",
        "            # 3. [A MUDANÇA MAIS IMPORTANTE] Converte a coluna para o tipo 'category'\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    # Específicos\n",
        "    if 'CS_SEXO' in df.columns:\n",
        "        df['CS_SEXO'] = df['CS_SEXO'].map({'F': 0, 'M': 1}).fillna(9).astype(int)\n",
        "    if 'CS_ESCOL_N' in df.columns:\n",
        "        df['CS_ESCOL_N'] = df['CS_ESCOL_N'].fillna(df['CS_ESCOL_N'].median() if df['CS_ESCOL_N'].isnull().sum() < len(df) else 0)\n",
        "        df['baixa_educacao'] = (df['CS_ESCOL_N'] <= 3).astype(int)\n",
        "\n",
        "    for col in ['SG_UF']:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else 'IGNORADO')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Engenharia de features\n",
        "    comorbidades = [c for c in ['DIABETES', 'PNEUMOPATI', 'CARDIOPATI', 'OBESIDADE', 'RENAL',\n",
        "                            'HEPATICA', 'IMUNODEPRE', 'SIND_DOWN'] if c in df.columns]\n",
        "    sintomas = [s for s in ['FEBRE', 'GARGANTA', 'DISPNEIA', 'FADIGA', 'SATURACAO', 'DESC_RESP']\n",
        "            if s in df.columns]\n",
        "\n",
        "    # Garanta que todas as colunas sejam numéricas antes de somar.\n",
        "    # O 'errors='coerce'' transforma qualquer valor não numérico em Nulo (NaN).\n",
        "    for col in comorbidades + sintomas:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "\n",
        "    # Agora a soma funcionará com segurança, pois todas as colunas são numéricas.\n",
        "    df['total_comorbidades'] = df[comorbidades].sum(axis=1) if comorbidades else 0\n",
        "    df['total_sintomas'] = df[sintomas].sum(axis=1) if sintomas else 0\n",
        "\n",
        "\n",
        "    if 'NU_IDADE_N' in df.columns:\n",
        "        bins = [0, 18, 30, 60, 80, 120]\n",
        "        labels = ['0-18', '19-30', '31-60', '61-80', '80+']\n",
        "        df['FAIXA_ETARIA'] = pd.cut(df['NU_IDADE_N'], bins=bins, labels=labels, right=False).astype(str)\n",
        "        df['idoso_com_comorbidade'] = ((df['NU_IDADE_N'] >= 60) & (df['total_comorbidades'] > 0)).astype(int)\n",
        "        df['interacao_idade_risco'] = np.minimum(df['NU_IDADE_N'] * df['total_comorbidades'], 100)\n",
        "\n",
        "    mapa_regioes = {\"AC\": \"Norte\", \"AM\": \"Norte\", \"AP\": \"Norte\", \"PA\": \"Norte\", \"RO\": \"Norte\", \"RR\": \"Norte\", \"TO\": \"Norte\",\n",
        "                    \"AL\": \"Nordeste\", \"BA\": \"Nordeste\", \"CE\": \"Nordeste\", \"MA\": \"Nordeste\", \"PB\": \"Nordeste\",\n",
        "                    \"PE\": \"Nordeste\", \"PI\": \"Nordeste\", \"RN\": \"Nordeste\", \"SE\": \"Nordeste\",\n",
        "                    \"DF\": \"Centro-Oeste\", \"GO\": \"Centro-Oeste\", \"MT\": \"Centro-Oeste\", \"MS\": \"Centro-Oeste\",\n",
        "                    \"ES\": \"Sudeste\", \"MG\": \"Sudeste\", \"RJ\": \"Sudeste\", \"SP\": \"Sudeste\",\n",
        "                    \"PR\": \"Sul\", \"RS\": \"Sul\", \"SC\": \"Sul\"}\n",
        "    if 'SG_UF' in df.columns:\n",
        "        df['REGIAO'] = df['SG_UF'].map(mapa_regioes).fillna('IGNORADO').astype(str)\n",
        "        if is_train and 'EVOLUCAO' in df.columns:\n",
        "            mortalidade_uf = df.groupby('SG_UF')['EVOLUCAO'].mean().to_dict()\n",
        "        if mortalidade_uf:\n",
        "            df['risco_uf'] = df['SG_UF'].map(mortalidade_uf).fillna(0)\n",
        "\n",
        "    # Proxy temporal (sem DT_SIN_PRI, use DT_NOTIFIC antes do drop)\n",
        "    if 'DT_NOTIFIC' in df.columns:\n",
        "        df['DT_NOTIFIC'] = pd.to_datetime(df['DT_NOTIFIC'], errors='coerce')\n",
        "        df['SEM_PRI_proxy'] = df['DT_NOTIFIC'].dt.isocalendar().week - 1\n",
        "        df['mes_notific'] = df['DT_NOTIFIC'].dt.month.fillna(6).astype(int)\n",
        "        df['delay_sint_notif'] = 3 + df['mes_notific'] * 0.5  # Proxy\n",
        "        df.drop('DT_NOTIFIC', axis=1, inplace=True)\n",
        "\n",
        "    # Drop final\n",
        "    #cols_to_drop = ['NU_IDADE_N', 'SG_UF']  # Mantenha CS_ESCOL_N\n",
        "    #df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
        "\n",
        "    # One-Hot e numérico\n",
        "    categorical_cols = [c for c in ['FAIXA_ETARIA', 'REGIAO'] if c in df.columns]\n",
        "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True, dtype=int)\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object':\n",
        "            le = LabelEncoder()\n",
        "            df[col] = le.fit_transform(df[col].astype(str))\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "\n",
        "    if not is_train and 'EVOLUCAO' in df.columns:\n",
        "        df = df.drop(columns=['EVOLUCAO'])\n",
        "\n",
        "    print(f\"Shape final: {df.shape}, Nulos totais: {df.isnull().sum().sum()}\")\n",
        "    return df, mortalidade_uf if is_train else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqp00MD-Jm3P",
        "outputId": "a0bafe4e-b430-4061-887e-dc6a1c9759e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropping DT_NOTIFIC early.\n",
            "Dropping OBES_IMC early.\n",
            "Dropping VOMITO early.\n",
            "Dropping TOSSE early.\n",
            "Dropping PUERPERA early.\n",
            "Dropping CO_RG_RESI early.\n",
            "Dropping ID_MN_RESI early.\n",
            "Shape final: (498320, 39), Nulos totais: 0\n"
          ]
        }
      ],
      "source": [
        "# 3. Pipeline\n",
        "# Preprocess\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_train_processed, mortalidade_uf = preprocess_data(df_train, is_train=True)\n",
        "df_train_processed = df_train_processed.dropna(subset=['EVOLUCAO'])\n",
        "X = df_train_processed.drop(columns=['EVOLUCAO'])\n",
        "y = df_train_processed['EVOLUCAO'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTKyZJX9ZHbI"
      },
      "source": [
        "## Divide os dados de forma estratégica e corrigir o desbalanceamento de classes no conjunto de treino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIUJ4SyaWXfT",
        "outputId": "5c3c0a61-eb3c-444d-8e05-e28cbe4b20f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanceado: EVOLUCAO\n",
            "0    0.5\n",
            "1    0.5\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Splits + SMOTE\n",
        "X_temp, X_holdout, y_temp, y_holdout = train_test_split(X, y, test_size=0.05, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.111, random_state=42, stratify=y_temp)\n",
        "smote = SMOTE(random_state=60)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
        "print(\"Balanceado:\", pd.Series(y_train_bal).value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzvK9DcNXu3d",
        "outputId": "e864ac37-1be8-4881-d713-652ead838c4b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ratio para scale_pos_weight: 1.90\n",
            "\n",
            "Iniciando a avaliação do XGBoost com Validação Cruzada...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [01:19:00] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [01:19:58] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [01:20:49] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [01:21:39] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [01:22:33] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Scores F1 do XGBoost em cada fold: [0.64263428 0.64743749 0.64288026 0.64525617 0.64041864]\n",
            "Média do F1-Score (CV) para XGBoost: 0.6437\n",
            "Desvio Padrão do F1-Score (CV) para XGBoost: 0.0024\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# --- Parâmetros Iniciais para o XGBoost ---\n",
        "# Estes são parâmetros iniciais razoáveis. O ideal é otimizá-los depois.\n",
        "\n",
        "# Ponto importante: tratamento de classes desbalanceadas no XGBoost\n",
        "# Calcule o 'scale_pos_weight' para ajudar o modelo com o desbalanceamento\n",
        "# A fórmula é: (número de amostras da classe negativa) / (número de amostras da classe positiva)\n",
        "ratio = len(y[y == 0]) / len(y[y == 1])\n",
        "print(f\"Ratio para scale_pos_weight: {ratio:.2f}\")\n",
        "\n",
        "params_iniciais_xgb = {\n",
        "    'objective': 'binary:logistic', # Objetivo para classificação binária\n",
        "    'eval_metric': 'logloss',       # Métrica para avaliação interna\n",
        "    'n_estimators': 1000,           # Número de árvores. Usaremos early stopping, então pode ser alto.\n",
        "    'learning_rate': 0.05,          # Taxa de aprendizado\n",
        "    'max_depth': 4,                 # Profundidade máxima da árvore (bom valor para começar)\n",
        "    'subsample': 0.8,               # Fração de amostras de treino por árvore\n",
        "    'colsample_bytree': 0.8,        # Fração de features por árvore\n",
        "    'gamma': 0.1,                   # Parâmetro de regularização\n",
        "    'scale_pos_weight': ratio,      # !! Essencial para classes desbalanceadas !!\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1,                   # Usar todos os cores do processador\n",
        "    'use_label_encoder': False      # Recomendação da biblioteca para evitar warnings\n",
        "}\n",
        "\n",
        "# Crie o modelo XGBoost com os parâmetros definidos\n",
        "modelo_xgb = xgb.XGBClassifier(**params_iniciais_xgb)\n",
        "\n",
        "# --- Avaliação com Validação Cruzada (A forma confiável) ---\n",
        "\n",
        "# Use os dados de treino COMPLETOS (X, y)\n",
        "X_treino_completo = X\n",
        "y_treino_completo = y\n",
        "\n",
        "# Crie os folds para a validação cruzada\n",
        "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Calcule os scores de F1 para cada fold\n",
        "print(\"\\nIniciando a avaliação do XGBoost com Validação Cruzada...\")\n",
        "f1_scores_xgb = cross_val_score(modelo_xgb, X_treino_completo, y_treino_completo, cv=cv_folds, scoring='f1')\n",
        "\n",
        "# Veja o resultado\n",
        "print(f\"\\nScores F1 do XGBoost em cada fold: {f1_scores_xgb}\")\n",
        "print(f\"Média do F1-Score (CV) para XGBoost: {np.mean(f1_scores_xgb):.4f}\")\n",
        "print(f\"Desvio Padrão do F1-Score (CV) para XGBoost: {np.std(f1_scores_xgb):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtJzwzfLRzYd",
        "outputId": "e9d5bd30-c911-4958-b43a-f93541235098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando o treinamento do modelo de baseline (Stacking)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [01:26:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [01:27:43] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [01:28:03] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [01:28:12] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [01:28:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [01:28:32] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento concluído!\n"
          ]
        }
      ],
      "source": [
        " #4. Treinamento Direto do Modelo (Baseline)\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Definimos os modelos base com parâmetros padrão\n",
        "base_models = [\n",
        "    ('lgbm', lgb.LGBMClassifier(random_state=42, verbose=-1)),\n",
        "    ('xgb', xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
        "]\n",
        "\n",
        "# Definimos o meta-modelo\n",
        "meta_model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Criamos o modelo Stacking\n",
        "# Usamos todo o X_train_bal para treinar\n",
        "baseline_model = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        ")\n",
        "\n",
        "print(\"Iniciando o treinamento do modelo de baseline (Stacking)...\")\n",
        "# Treinamos diretamente nos dados de treino (balanceados)\n",
        "baseline_model.fit(X_train_bal, y_train_bal)\n",
        "print(\"Treinamento concluído!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABU8kbvOR3IW",
        "outputId": "b4ca0878-066a-4152-88dc-0bdb0d649ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Avaliando o modelo no conjunto de Holdout...\n",
            "Resultado com threshold padrão (0.5):\n",
            "F1-Score no Holdout: 0.6105\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.81      0.80     16314\n",
            "           1       0.62      0.60      0.61      8602\n",
            "\n",
            "    accuracy                           0.74     24916\n",
            "   macro avg       0.71      0.70      0.71     24916\n",
            "weighted avg       0.73      0.74      0.74     24916\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 5. Avaliação no Holdout\n",
        "print(\"\\nAvaliando o modelo no conjunto de Holdout...\")\n",
        "# Fazemos a previsão de probabilidade nos dados de holdout (que não foram usados no treino)\n",
        "y_pred_proba_holdout = baseline_model.predict_proba(X_holdout)[:, 1]\n",
        "\n",
        "# Usamos um threshold padrão de 0.5 para começar\n",
        "y_pred_final = (y_pred_proba_holdout > 0.5).astype(int)\n",
        "\n",
        "print(f\"Resultado com threshold padrão (0.5):\")\n",
        "print(f\"F1-Score no Holdout: {f1_score(y_holdout, y_pred_final):.4f}\")\n",
        "print(classification_report(y_holdout, y_pred_final))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FXox3rgR5P7",
        "outputId": "8604e4da-a4cb-4403-8ab9-87bb0c7fa0c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preparando o arquivo de submissão...\n",
            "Dropping DT_NOTIFIC early.\n",
            "Dropping OBES_IMC early.\n",
            "Dropping VOMITO early.\n",
            "Dropping TOSSE early.\n",
            "Dropping PUERPERA early.\n",
            "Dropping CO_RG_RESI early.\n",
            "Dropping ID_MN_RESI early.\n",
            "Shape final: (124581, 39), Nulos totais: 0\n",
            "Arquivo 'submission_bin.csv' criado com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# 6. Submissão (se necessário)\n",
        "print(\"\\nPreparando o arquivo de submissão...\")\n",
        "df_test = pd.read_csv(\"test.csv\")\n",
        "df_test_processed, _ = preprocess_data(df_test, is_train=False, mortalidade_uf=mortalidade_uf)\n",
        "\n",
        "# Garantir que as colunas do df_test sejam as mesmas do df de treino\n",
        "df_test_processed = df_test_processed.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "# Previsão nos dados de teste\n",
        "predictions = baseline_model.predict_proba(df_test_processed)[:, 1]\n",
        "\n",
        "submission_ids = df_test['ID'] if 'ID' in df_test else df_test.index\n",
        "submission_df = pd.DataFrame({'ID': submission_ids, 'EVOLUCAO': (predictions > 0.5).astype(int)})\n",
        "submission_df.to_csv('submission_bin.csv', index=False)\n",
        "print(\"Arquivo 'submission_bin.csv' criado com sucesso!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNa+jwUXz3o60tchK5Yq2Qw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}